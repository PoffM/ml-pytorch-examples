{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torchmetrics\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from collections import OrderedDict\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# train_dataset, val_dataset = random_split(train_dataset, [55000, 5000])\n",
    "train_dataset = MNIST(root=\"../../data\", download=True, transform=transforms.ToTensor(), train=True)\n",
    "test_dataset = MNIST(root=\"../../data\", transform=transforms.ToTensor(), train=False)\n",
    "\n",
    "train_dataset, val_dataset = random_split(train_dataset, [55000, 5000])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "  dataset=train_dataset,\n",
    "  batch_size=128,\n",
    "  shuffle=True,\n",
    "  num_workers=11,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "  dataset=val_dataset,\n",
    "  batch_size=128,\n",
    "  num_workers=11,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "  dataset=test_dataset,\n",
    "  batch_size=128,\n",
    "  num_workers=0,\n",
    ")\n",
    "\n",
    "class MnistClassifierModel(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.seq = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv2d(1, 32, 3, 1)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('maxpool1', nn.MaxPool2d(2)),\n",
    "            ('conv2', nn.Conv2d(32, 64, 3, 1)),\n",
    "            ('relu2', nn.ReLU()),\n",
    "            ('maxpool2', nn.MaxPool2d(2)),\n",
    "            ('flatten', nn.Flatten()),\n",
    "            ('lin1', nn.Linear(1600, 512)),\n",
    "            ('relu3', nn.ReLU()),\n",
    "            ('dropout2', nn.Dropout(0.5)),\n",
    "            ('lin2', nn.Linear(512, 10)),\n",
    "        ]))\n",
    "\n",
    "        self.train_acc = torchmetrics.Accuracy(task='multiclass', num_classes=10).to(device)\n",
    "        self.val_acc = torchmetrics.Accuracy(task='multiclass', num_classes=10).to(device)\n",
    "        self.test_acc = torchmetrics.Accuracy(task='multiclass', num_classes=10).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "    \n",
    "    def _shared_step(self, batch):\n",
    "        features, true_labels = batch\n",
    "        logits = self(features)\n",
    "        loss = F.cross_entropy(logits, true_labels)\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        return loss, true_labels, predictions\n",
    "    \n",
    "    def training_step(self, batch, batch_idx: int):\n",
    "        loss, true_labels, predictions = self._shared_step(batch)\n",
    "\n",
    "        self.log('train_loss', loss)\n",
    "\n",
    "        # Track accuracy\n",
    "        self.train_acc(predictions, true_labels)\n",
    "        self.log('train_acc', self.train_acc, prog_bar=True, on_epoch=True, on_step=False)\n",
    "\n",
    "        return loss # this is passed to the optimizer for training\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx: int):\n",
    "        loss, true_labels, predictions = self._shared_step(batch)\n",
    "\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "\n",
    "        # Track accuracy\n",
    "        self.val_acc(predictions, true_labels)\n",
    "        self.log('val_acc', self.val_acc, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx: int):\n",
    "        loss, true_labels, predictions = self._shared_step(batch)\n",
    "\n",
    "        # Track accuracy\n",
    "        self.test_acc(predictions, true_labels)\n",
    "        self.log('accuracy', self.test_acc, prog_bar=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters())\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | seq       | Sequential         | 843 K  | train\n",
      "1 | train_acc | MulticlassAccuracy | 0      | train\n",
      "2 | val_acc   | MulticlassAccuracy | 0      | train\n",
      "3 | test_acc  | MulticlassAccuracy | 0      | train\n",
      "---------------------------------------------------------\n",
      "843 K     Trainable params\n",
      "0         Non-trainable params\n",
      "843 K     Total params\n",
      "3.375     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MnistClassifierModel(\n",
      "  (seq): Sequential(\n",
      "    (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (relu1): ReLU()\n",
      "    (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (relu2): ReLU()\n",
      "    (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (lin1): Linear(in_features=1600, out_features=512, bias=True)\n",
      "    (relu3): ReLU()\n",
      "    (dropout2): Dropout(p=0.5, inplace=False)\n",
      "    (lin2): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      "  (train_acc): MulticlassAccuracy()\n",
      "  (val_acc): MulticlassAccuracy()\n",
      "  (test_acc): MulticlassAccuracy()\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0594954298446fb9606eaad0c4fba9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1f97508c954a1a8c35db3469b02341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7c110197a74ed18493ffe19c2e48b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "736f54bc56174da88bab8c8d67cf58cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc0171e152240a78c10284c019747fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "model = MnistClassifierModel().to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "trainer = L.Trainer(\n",
    "  max_epochs=3,\n",
    "  accelerator='gpu',\n",
    "  devices='auto' # Use all available GPUs if applicable\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "  model,\n",
    "  train_dataloaders=train_loader,\n",
    "  val_dataloaders=val_loader\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc0642322fe468eb74089d4d58a9679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([128, 10])\n",
      "torch.Size([16, 10])\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        accuracy            0.9886000156402588\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.9886000156402588}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "@model.register_forward_hook\n",
    "def hook(module, input, output):\n",
    "  print(output.shape)\n",
    "\n",
    "trainer.test(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-pytorch-P31O4-yn-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
