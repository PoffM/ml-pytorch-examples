{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(9216, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.seq(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1], Iter[100] Loss: 0.81\n",
      "Epoch[1], Iter[200] Loss: 0.52\n",
      "Epoch[1], Iter[300] Loss: 0.38\n",
      "Epoch[1], Iter[400] Loss: 0.35\n",
      "Training Results - Epoch[1] Avg accuracy: 0.95 Avg loss: 0.15\n",
      "Validation Results - Epoch[1] Avg accuracy: 0.96 Avg loss: 0.15\n",
      "Epoch[2], Iter[500] Loss: 0.38\n",
      "Epoch[2], Iter[600] Loss: 0.26\n",
      "Epoch[2], Iter[700] Loss: 0.21\n",
      "Epoch[2], Iter[800] Loss: 0.19\n",
      "Epoch[2], Iter[900] Loss: 0.27\n",
      "Training Results - Epoch[2] Avg accuracy: 0.97 Avg loss: 0.11\n",
      "Validation Results - Epoch[2] Avg accuracy: 0.97 Avg loss: 0.11\n",
      "Epoch[3], Iter[1000] Loss: 0.17\n",
      "Epoch[3], Iter[1100] Loss: 0.17\n",
      "Epoch[3], Iter[1200] Loss: 0.20\n",
      "Epoch[3], Iter[1300] Loss: 0.15\n",
      "Epoch[3], Iter[1400] Loss: 0.21\n",
      "Training Results - Epoch[3] Avg accuracy: 0.98 Avg loss: 0.06\n",
      "Validation Results - Epoch[3] Avg accuracy: 0.98 Avg loss: 0.06\n",
      "Epoch[4], Iter[1500] Loss: 0.28\n",
      "Epoch[4], Iter[1600] Loss: 0.07\n",
      "Epoch[4], Iter[1700] Loss: 0.10\n",
      "Epoch[4], Iter[1800] Loss: 0.15\n",
      "Training Results - Epoch[4] Avg accuracy: 0.98 Avg loss: 0.05\n",
      "Validation Results - Epoch[4] Avg accuracy: 0.98 Avg loss: 0.05\n",
      "Epoch[5], Iter[1900] Loss: 0.09\n",
      "Epoch[5], Iter[2000] Loss: 0.08\n",
      "Epoch[5], Iter[2100] Loss: 0.11\n",
      "Epoch[5], Iter[2200] Loss: 0.13\n",
      "Epoch[5], Iter[2300] Loss: 0.05\n",
      "Training Results - Epoch[5] Avg accuracy: 0.99 Avg loss: 0.04\n",
      "Validation Results - Epoch[5] Avg accuracy: 0.99 Avg loss: 0.05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "State:\n",
       "\titeration: 2345\n",
       "\tepoch: 5\n",
       "\tepoch_length: 469\n",
       "\tmax_epochs: 5\n",
       "\toutput: 0.054081257432699203\n",
       "\tbatch: <class 'list'>\n",
       "\tmetrics: <class 'dict'>\n",
       "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
       "\tseed: <class 'NoneType'>\n",
       "\ttimes: <class 'dict'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "\n",
    "from ignite.engine import Engine, Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from ignite.contrib.handlers import TensorboardLogger, global_step_from_engine\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Net().to(device)\n",
    "\n",
    "data_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    MNIST(download=True, root=\"../data\", transform=data_transform, train=True), batch_size=128, shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    MNIST(download=True, root=\"../data\", transform=data_transform, train=False), batch_size=256, shuffle=False\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device)\n",
    "\n",
    "val_metrics = {\n",
    "    \"accuracy\": Accuracy(),\n",
    "    \"loss\": Loss(criterion)\n",
    "}\n",
    "\n",
    "train_evaluator = create_supervised_evaluator(model, metrics=val_metrics, device=device)\n",
    "val_evaluator = create_supervised_evaluator(model, metrics=val_metrics, device=device)\n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED(every=100))\n",
    "def log_training_loss(engine: Engine):\n",
    "    print(f\"Epoch[{engine.state.epoch}], Iter[{engine.state.iteration}] Loss: {engine.state.output:.2f}\")\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(trainer: Engine):\n",
    "    train_evaluator.run(train_loader)\n",
    "    metrics = train_evaluator.state.metrics\n",
    "    print(f\"Training Results - Epoch[{trainer.state.epoch}] Avg accuracy: {metrics['accuracy']:.2f} Avg loss: {metrics['loss']:.2f}\")\n",
    "\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer: Engine):\n",
    "    val_evaluator.run(val_loader)\n",
    "    metrics = val_evaluator.state.metrics\n",
    "    print(f\"Validation Results - Epoch[{trainer.state.epoch}] Avg accuracy: {metrics['accuracy']:.2f} Avg loss: {metrics['loss']:.2f}\")\n",
    "\n",
    "# Score function to return current value of any metric we defined above in val_metrics\n",
    "def score_function(engine):\n",
    "    return engine.state.metrics[\"accuracy\"]\n",
    "\n",
    "# Checkpoint to store n_saved best models wrt score function\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    \"checkpoint\",\n",
    "    n_saved=2,\n",
    "    filename_prefix=\"best\",\n",
    "    score_function=score_function,\n",
    "    score_name=\"accuracy\",\n",
    "    global_step_transform=global_step_from_engine(trainer), # helps fetch the trainer's state\n",
    ")\n",
    "  \n",
    "# Save the model after every epoch of val_evaluator is completed\n",
    "val_evaluator.add_event_handler(Events.COMPLETED, model_checkpoint, {\"model\": model})\n",
    "\n",
    "# Define a Tensorboard logger\n",
    "tb_logger = TensorboardLogger(log_dir=\"tb-logger\")\n",
    "\n",
    "# Attach handler to plot trainer's loss every 100 iterations\n",
    "tb_logger.attach_output_handler(\n",
    "    trainer,\n",
    "    event_name=Events.ITERATION_COMPLETED(every=100),\n",
    "    tag=\"training\",\n",
    "    output_transform=lambda loss: {\"batch_loss\": loss},\n",
    ")\n",
    "\n",
    "# Attach handler for plotting both evaluators' metrics after every epoch completes\n",
    "for tag, evaluator in [(\"training\", train_evaluator), (\"validation\", val_evaluator)]:\n",
    "    tb_logger.attach_output_handler(\n",
    "        evaluator,\n",
    "        event_name=Events.EPOCH_COMPLETED,\n",
    "        tag=tag,\n",
    "        metric_names=\"all\",\n",
    "        global_step_transform=global_step_from_engine(trainer),\n",
    "    )\n",
    "\n",
    "trainer.run(train_loader, max_epochs=5)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
